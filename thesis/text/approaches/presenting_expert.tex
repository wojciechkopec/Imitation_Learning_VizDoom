\section{Świadomie prezentujący ekspert}\label{presenting_expert}
W sekcji \ref{behavioral_cloning} opisano agenta budującego klasyfikator (stan $\to$ akcja) na podstawie trajektorii zebranych podczas gry eksperta. Uzyskany agent zachowywał się sensownie, ale problem stanowiło między innymi blokowanie się w rogach labiryntu i wchodzenie na miny. Główną praktyczną wadą metody \ref{dagger}, która miała na celu zaradzenie temu, jest niespójność zachowań eksperta podczas pierwszej (ciągłej) prezentacji i zachowań podczas krótkich prezentacji podczas gry agenta oraz uciążliwość obserwacji i przejmowania sterowania od agenta w trakcie gry.

Problem wchodzenia w ściany, dla przykładu, jest łatwo zauważalny podczas obserwacji działania agenta. Oczywistym jest też powód jego występowania - ekspert, w przeciwieństwie do agenta, pamięta jak dotarł do danego stanu i znajdując się w rogu pamięta, w którą stronę powinien z niego wyjść. Badani agenci mogą pamiętać tylko kilka ostatnich odwiedzonych klatek i nie pamiętają swoich trajektorii. Dlatego klasyfikator nauczony na trajektoriach eksperta nie ma wystarczającej informacji żeby rozróżnić konieczność wychodzenia z rogu obracając się w prawo bądź w lewo.

Rozwiązaniem jest powtórne zebranie trajektorii eksperta, kładąc przy prezentacji nacisk na zachowywanie się w sposób spójny i ułatwiający klasyfikatorowi skuteczną naukę. Możliwe jest też pokazywanie rozwiązań sytuacji, które wcześniej sprawiały klasyfikatorowi problem, w celu pokazania poprawnego zachowania w danej sytuacji.

Oczywiście, takie zachowanie eksperta skutkuje uzyskiwaniem przez niego nieoptymalnych wyników, a co za tym idzie wyniki możliwe do osiągnięcia przez idealnie odwzorowującego agenta też są niższe. W praktyce różnica pomiędzy wynikami eksperta i agenta powinna się zmniejszyć dzięki świadomej prezentacji, skutkując wyższymi wynikami osiąganymi przez agenta.

\subsection{Algorytm}

Algorytm działania jest nastepujący:
\begin{enumerate}
\item{Naucz agenta na podstawie trajektorii, dla których uzyskano najlepsze wyniki}
\item{Przeanalizuj działanie agenta, szukając nieoptymalnych zachowań, które mogą wynikać z niedoskonałości prezentacji eksperta}
\item{Wygeneruj nowe trajektorie, eliminując zauważone niedoskonałości}
\end{enumerate}

Przykładowymi zachowaniami mogą być:
\begin{itemize}
\item{Problem: agent blokuje się w rogach labiryntu. Przeciwdziałanie: będąc w rogu labiryntu ekspert zawsze odwraca się w lewą stronę.}
\item{Problem: agent nie radzi sobie, gdy przeciwnicy podejdą zbyt blisko. Przeciwdziałanie: ekspert pozwala przeciwnikom podejść do siebie przed wyeliminowaniem ich.}
\end{itemize}

\subsection{Techniczna implementacja}

Techniczna implementacja jest identyczna z opisaną w rozdziale \ref{behavioral_cloning}.

\subsection{Zachowanie}
Eksperymenty były prowadzone na scenariuszach \nameref{scenario_hgs} i \nameref{scenario_dtc}.

W scenariuszu Obrona środka ekspert podczas świadomej prezentacji powstrzymywał się od strzelania do odległych przeciwników i świadomie preferował strzelanie do szybszych przeciwników. Świadoma prezentacja zmniejszyła liczbę niepotrzebnych strzałów nauczonego agenta.

W scenariuszu Trudne zbieranie apteczek ekspert podczas świadomej prezentacji zawsze wychodził z rogów obracając się w tę samą stronę i czasami odwracał się od tras z minami. Świadoma prezentacja prawie całkowicie wyeliminowała wpadanie w nieskończone pętle ruchów w rogach. W niektórych sytuacjach zdarzało się, że agent zawracał za to w ciasnych, ale możliwych do przejścia korytarzach - było to zachowanie wyraźnie nieoptymalne, ale bez zauważalnego wpływu na osiągane wyniki. Niestety, świadoma prezentacja nie wyeliminowała wchodzenia w miny. Wynik punktowy agenta zwiększył się istotnie po zastosowaniu świadomej prezentacji.

To, jak ważna jest świadoma prezentacja widoczne było przy zwiększaniu wielkości trajektorii eksperta użytych do nauki klasyfikatora. Dla obu scenariuszy agent nauczony na podstawie małej liczby trajektorii świadomego eksperta przewyższał agenta nauczonego na większej liczbie trajektorii nieświadomego eksperta i agenta nauczonego na mieszance trajektorii. 
 
\subsection{Wnioski}

Dla obu scenariuszy świadoma prezentacja eksperta jest prostym i bardzo skutecznym sposobem eliminowania części oczywistych błędów popełnianych przez agenta. Dla niektórych problemów i sytuacji może wypełniać zadanie postawione przed metodą agregacji zbioru danych w wygodniejszy i bardziej naturalny sposób.

Świadoma prezentacja nie jest formalną metodą, a raczej wytyczną. Dzięki temu można ją z powodzeniem stosować w połączeniu z innymi technikami uczenia z ekspertem.
